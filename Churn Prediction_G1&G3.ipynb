{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mg_ZAS0B2slE"
   },
   "source": [
    "___\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"https://docs.google.com/uc?id=1lY0Uj5R04yMY3-ZppPWxqCr5pvBLYPnV\" class=\"img-fluid\" alt=\"CLRSWY\"></p>\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8EjVhtzq2slH"
   },
   "source": [
    "# WELCOME!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JqV3cXW-2slL"
   },
   "source": [
    "Welcome to \"***Employee Churn Analysis Project***\". This is the second project of Capstone Project Series, which you will be able to build your own classification models for a variety of business settings. \n",
    "\n",
    "Also you will research what is Employee Churn?, How it is different from customer churn, Exploratory data analysis and visualization of employee churn dataset using ***matplotlib*** and ***seaborn***, model building and evaluation using python ***scikit-learn*** and ***Tensorflow-Keras*** packages. \n",
    "\n",
    "You will be able to implement classification techniques in Python. Using Scikit-Learn allowing you to successfully make predictions with Distance Based, Bagging, Boosting algorithms for this project. On the other hand, for Deep Learning you will use Tensorflow-Keras. \n",
    "\n",
    "At the end of the project, you will have the opportunity to deploy your model using *Streamlit*.\n",
    "\n",
    "Before diving into the project, please take a look at the determines and project structure.\n",
    "\n",
    "- NOTE: This project assumes that you already know the basics of coding in Python and are familiar with model deployement as well as the theory behind Distance Based, Bagging, Boosting algorithms, and Confusion Matrices. You can try more models and methods beside these to improve your model metrics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4oRnVXpS2slN"
   },
   "source": [
    "# #Determines\n",
    "In this project you have HR data of a company. A study is requested from you to predict which employee will churn by using this data.\n",
    "\n",
    "The HR dataset has 14,999 samples. In the given dataset, you have two types of employee one who stayed and another who left the company.\n",
    "\n",
    "You can describe 10 attributes in detail as:\n",
    "- ***satisfaction_level:*** It is employee satisfaction point, which ranges from 0-1.\n",
    "- ***last_evaluation:*** It is evaluated performance by the employer, which also ranges from 0-1.\n",
    "- ***number_projects:*** How many of projects assigned to an employee?\n",
    "- ***average_monthly_hours:*** How many hours in averega an employee worked in a month?\n",
    "- **time_spent_company:** time_spent_company means employee experience. The number of years spent by an employee in the company.\n",
    "- ***work_accident:*** Whether an employee has had a work accident or not.\n",
    "- ***promotion_last_5years:*** Whether an employee has had a promotion in the last 5 years or not.\n",
    "- ***Departments:*** Employee's working department/division.\n",
    "- ***Salary:*** Salary level of the employee such as low, medium and high.\n",
    "- ***left:*** Whether the employee has left the company or not.\n",
    "\n",
    "First of all, to observe the structure of the data, outliers, missing values and features that affect the target variable, you must use exploratory data analysis and data visualization techniques. \n",
    "\n",
    "Then, you must perform data pre-processing operations such as ***Scaling*** and ***Encoding*** to increase the accuracy score of Gradient Descent Based or Distance-Based algorithms. \n",
    "\n",
    "You are asked to perform ***Cluster Analysis*** based on the information you obtain during exploratory data analysis and data visualization processes. The purpose of clustering analysis is to cluster data with similar characteristics.\n",
    "\n",
    "Once the data is ready to be applied to the model, you must ***split the data into train and test***. Then build a model to predict whether employees will churn or not. Train your models with your train set, test the success of your model with your test set. \n",
    "\n",
    "Try to make your predictions by using the *** Classification Algorithms***. You can use the related modules of the ***scikit-learn*** and ***Tensorflow-Keras*** library. You can use scikit-learn ***Classification Metrics*** module for accuracy calculation.\n",
    "\n",
    "In the final step, you will deploy your model using Streamlit tool.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97xzRLNj2slO"
   },
   "source": [
    "# #Tasks\n",
    "\n",
    "#### 1. Exploratory Data Analysis\n",
    "- EDA is an initial process of analysis, in which you can summarize characteristics of data such as pattern, trends, outliers, and hypothesis testing using descriptive statistics and visualization.\n",
    "- In the given dataset, you have two types of employee one who stayed and another who left the company. So, you can divide data into two groups and compare their characteristics.\n",
    "\n",
    "#### 2. Data Visualization\n",
    "- Explore your data via visualizations to find-out:\n",
    " - What can be the reason of the churn?\n",
    " - Behavioral analysis of churns and not churns ..... etc.\n",
    "\n",
    "#### 3. Cluster Analysis\n",
    "- Apply ***clustering algorithms*** and writedown your conclusions about the clusters you created. \n",
    "\n",
    "#### 4. Predictive Model Building\n",
    "- Split Data as Train and Test set\n",
    "- Built Classification Models(at least four models) and Evaluate Model Performances\n",
    "\n",
    "#### 5. Model Deployement\n",
    "\n",
    "- Save and Export the Best Model\n",
    "- Deploy best model via Streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TyrWBiyM2sld"
   },
   "source": [
    "## #Importing Modules and Predefined Functions#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DVuK5K1XmEld"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.preprocessing import PowerTransformer, StandardScaler\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn.metrics import silhouette_samples,silhouette_score\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from yellowbrick.cluster import KElbowVisualizer, SilhouetteVisualizer, InterclusterDistance\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import cufflinks as cf\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "cf.go_offline()\n",
    "from sklearn.preprocessing import PowerTransformer, StandardScaler, scale, OneHotEncoder, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score, calinski_harabasz_score, davies_bouldin_score, adjusted_rand_score, mean_squared_error, mean_absolute_error, r2_score, accuracy_score, f1_score, recall_score, precision_score, confusion_matrix, classification_report, make_scorer, precision_recall_curve, PrecisionRecallDisplay\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate, train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils import class_weight\n",
    "from scikitplot.metrics import plot_precision_recall, plot_roc, precision_recall_curve\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from yellowbrick.cluster import KElbowVisualizer, SilhouetteVisualizer, InterclusterDistance\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import math\n",
    "import pickle\n",
    "from scipy.stats import chi2_contingency, skew, stats\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import Adam, Adadelta, RMSprop, Nadam\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.models import load_model\n",
    "from ipywidgets import interact\n",
    "from scipy.stats import levene\n",
    "from livelossplot import PlotLossesKerasTF\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('/content/drive/Data Science Capstone Projects/2 Employee Churn Analysis Project/HR_Dataset.csv', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YYa4hXuRmEgR"
   },
   "outputs": [],
   "source": [
    "df0 = pd.read_csv(\"HR_Dataset.csv\")\n",
    "df0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLTGi7q02slP"
   },
   "source": [
    "## 1. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Qd_Mxw-2sl9"
   },
   "outputs": [],
   "source": [
    "df = df0.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uxWS1wEymnCS"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and standardize the column names\n",
    "\n",
    "import skimpy\n",
    "from skimpy import clean_columns\n",
    "\n",
    "df = clean_columns(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the descriptive information of the object columns\n",
    "\n",
    "df.describe(include='object').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dupliocated Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 3008 duplicated rows. \n",
    "# However, it is very likely that the data is for different people with the same data.\n",
    "# So, we will keep those rows in our data set and not drop them.\n",
    "\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def check_df(col):\n",
    "  print('column name : ', col)\n",
    "  print('--------------------------------')\n",
    "  #print('Per_of_Nulls           : ', '%', round(df[col].isnull().sum()*100/len(df), 2))\n",
    "  #print('Num_of_Nulls           : ', df[col].isnull().sum())\n",
    "  print('Num_of_Unique_Values   : ', df[col].nunique())\n",
    "  print(df[col].value_counts(dropna = False))\n",
    "  print(\"*\"*30)\n",
    "  print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "for col in df.columns :\n",
    "  check_df(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see, in the data set, the percentage of employees's who left the company(1) and who are sill working(0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function to show the percentage of unique values in a feature.\n",
    "\n",
    "def perc_col(df, col):\n",
    "    for i in sorted(df[col].unique(), reverse=True):\n",
    "        percentage = 100 * df[col].value_counts()[i] / len(df)\n",
    "        print('%s: %.1f%%' % (i, percentage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_col(df,'left')\n",
    "\n",
    "# This seems to be an unbalanced data set. So, we need to take this into consideration when using ML/DL models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_col(df,'salary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_col(df,'departments')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Limitations of the Data Set in terms of Employee Churn Prediction\n",
    "* The data set doesn't have some important demographic information (e.g. Age, Gender, Education, Maritial status, Distance from home etc) of the employees\n",
    "* We don't have enough information/data to decide whether to keep or drop duplicated rows. We may need to check how each case affects the predictions in ML/DL.\n",
    "* It is not a \"big enough\" data set to employ DL models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PsO9Iew2smG"
   },
   "source": [
    "## 2. Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. An overall investigation of the data set and target feature ('left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue = \"left\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution plots help us understand the data better, with this visualization we are able to see how our data is distributed and if there are any outliers in the data sets. \n",
    "For this purpose, we are going to use the histogram for every numerical feature in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visulazing the distibution of the data for every feature\n",
    "df.hist(bins=30, figsize=(20,20), color='b', alpha=0.6);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(), annot=True, cmap =\"coolwarm\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The highest correlation of the target feature is with \"satisfaction_level\" which is 0.39.\n",
    "\n",
    "\n",
    "ax = df.corr()[\"left\"].drop(\"left\").sort_values().plot.barh()\n",
    "ax.bar_label(ax.containers[0], fmt='%.2f');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "\n",
    "sns.countplot(x = df.left);\n",
    "ax.bar_label(ax.containers[0], size=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_left = df.left.value_counts() / len(df) * 100\n",
    "perc_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the percentage of employees who left and visualize it with a pieplot\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "plt.pie(x=perc_left.values,\n",
    "        labels = ['stayed','left'],\n",
    "        explode=[0.1, 0],\n",
    "        shadow=True,\n",
    "        autopct=\"%.1f%%\",\n",
    "       textprops={\"fontsize\": 11},\n",
    "       colors=[\"lightskyblue\", \"gold\"])\n",
    "plt.legend(labels=['stayed','left'])\n",
    "plt.title(\"Percentage of Churn\", fontsize=15, pad=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Churn ratio of employee by Salary Level\n",
    "pd.DataFrame(df.groupby('salary')['left'].mean()).sort_values('left',ascending=False).plot(kind='bar');\n",
    "pd.DataFrame(df.groupby('salary')['left'].mean()).sort_values('left',ascending=False).round(3).T*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Churn ratio of employee by Department\n",
    "pd.DataFrame(df.groupby('departments')['left'].mean()).sort_values('left',ascending=False).plot(kind='bar',figsize=(12,4))\n",
    "pd.DataFrame(df.groupby('departments')['left'].mean()).sort_values('left',ascending=False).round(3).T*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Categorical Column Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_column_investigation(col_name):\n",
    "    \"\"\"First Plot: Pie chart for categorical column to see the percentage of each value\n",
    "       Second Plot: Count plot for categorical column to see the count for each value\n",
    "       Third Plot: Number of counts separated by Number of Employees left the company\"\"\"\n",
    "\n",
    "    f, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    df[col_name].value_counts().plot.pie(autopct='%1.1f%%', ax=ax[0], shadow=True, cmap='Set2')\n",
    "    ax[0].set_title(f'Distribution of {col_name}')\n",
    "    \n",
    "    df[col_name].value_counts().plot.bar(ax=ax[1], cmap='Set2')\n",
    "    ax[1].set_title(f'Number of Employees by {col_name}')\n",
    "    ax[1].set_ylabel('Count')\n",
    "    ax[1].set_xlabel(f'{col_name}')\n",
    "    \n",
    "    sns.countplot(x=col_name, hue='left', data=df, ax=ax[2], palette='Set2')\n",
    "    ax[2].set_title(f'Number of Employees left by {col_name}')\n",
    "    ax[2].set_xlabel(f'{col_name}', )\n",
    "    ax[2].set_ylabel('Count')\n",
    "    ax[2].set_xticklabels(ax[2].get_xticklabels(), rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1. Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_column_investigation(\"salary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "satisfaction_salary = pd.DataFrame(df.groupby('salary').satisfaction_level.mean()).sort_values('satisfaction_level',ascending=False)\n",
    "\n",
    "satisfaction_salary.plot(kind='bar',figsize=(8,4))\n",
    "satisfaction_salary.T.round(3)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2. Departments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_column_investigation(\"departments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from matplotlib.cm import get_cmap\n",
    "import numpy as np\n",
    "\n",
    "def magma_color_func(word=None, font_size=None, position=None, orientation=None, font_path=None, random_state=None):\n",
    "    cmap = get_cmap('magma')\n",
    "    return tuple(int(x * 255) for x in cmap(random_state.random()))\n",
    "\n",
    "data = df.departments.value_counts()\n",
    "\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='black', color_func=magma_color_func).generate_from_frequencies(data)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "satisfaction_departments = pd.DataFrame(df.groupby('departments').satisfaction_level.mean()).sort_values('satisfaction_level',ascending=False)\n",
    "\n",
    "satisfaction_departments.plot(kind='bar',figsize=(8,4))\n",
    "satisfaction_departments.T.round(3)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The function (categorical_column_investigation) can be used for some numerical features too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_column_investigation(\"time_spend_company\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Numerical Column Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into two data sets \"df_left\" and \"df_stayed\" to be used for future visualizations.\n",
    "\n",
    "df_left = df[df['left'] == 1]\n",
    "df_stayed = df[df['left']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the distribution of the features with less less than 10 unique values on a countplot.\n",
    "numerical_cols = ['number_project', 'time_spend_company', 'work_accident','left', 'promotion_last_5years']\n",
    "\n",
    "plt.figure(figsize=(20,4))\n",
    "\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    ax = plt.subplot(1, len(numerical_cols), i+1)\n",
    "    sns.countplot(x=str(col), data=df)\n",
    "    ax.set_title(f\"{col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We define a function to show the two plots for investigation of numerical features. \n",
    "1. ***KDE plots*** for the distribution of variables and \n",
    "2. ***The boxplot*** for statistical investigation.\n",
    "\n",
    "Note: The columns with binary values ('Work_accident', 'promotion_last_5years) do not need to be invastigated with this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_colum_investigaton(col_name):\n",
    "    f,ax = plt.subplots(1,3, figsize=(18,6))\n",
    "    sns.kdeplot(df_left[col_name], label='Employees who left', ax=ax[0], shade=True, color='red').set(title='As two seperate data sets')\n",
    "    sns.kdeplot(df_stayed[col_name], label='Employees who stayed', ax=ax[0], shade=True, color='green')\n",
    "    sns.kdeplot(data=df, x=col_name, hue='left', ax=ax[1], shade=True).set(title='As a single data set')\n",
    "\n",
    "    sns.boxplot(y=col_name, x='left',data=df, palette='Set2', ax=ax[2]).set(title=f\"{col_name} by churn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1. Satisfaction Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_colum_investigaton('satisfaction_level')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2. Last Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_colum_investigaton('last_evaluation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3. Number of Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_colum_investigaton('number_project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stayed.number_project.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: There are some potential outliers in df_stayed data set.\n",
    "However, when we check the value counts, we can see that these are realistic numbers and NOT outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.4. Average Monthly Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_colum_investigaton('average_montly_hours')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.5. Time Spent at the Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_colum_investigaton('time_spend_company')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stayed.time_spend_company.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Similar to the 'number_project', there are some potential outliers in df_stayed data set.\n",
    "However, when we check the value counts, we can see that these are realistic numbers and NOT outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.6. Work Accident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_column_investigation(\"work_accident\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have noticed a negative correlation between work accident and churn rate.\n",
    "\n",
    "Percentage of people who had accident and left is less than that of employees who had accident and stayed.\n",
    "\n",
    "This was unexpected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"departments\")[\"work_accident\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accident_by_departments = pd.DataFrame(df.groupby('departments').work_accident.mean()).sort_values('work_accident',ascending=False)\n",
    "accident_by_departments.plot(kind='bar',figsize=(8,4))\n",
    "plt.title(\"Percentage of Work Accident by Departments\");\n",
    "\n",
    "accident_by_departments.T.round(3)*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accident_by_departments = pd.DataFrame(df.groupby('salary').work_accident.mean()).sort_values('work_accident',ascending=False)\n",
    "accident_by_departments.plot(kind='bar',figsize=(8,4))\n",
    "plt.title(\"Percentage of Work Accident by Salary\");\n",
    "\n",
    "accident_by_departments.T.round(3)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accident_by_departments = pd.DataFrame(df_left.groupby('salary').work_accident.mean()).sort_values('work_accident',ascending=False)\n",
    "accident_by_departments.plot(kind='bar',figsize=(8,4))\n",
    "plt.title(\"Percentage of Work Accident by Salary\");\n",
    "\n",
    "accident_by_departments.T.round(3)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  2.3.7. Promotion Last 5 Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_column_investigation(\"promotion_last_5years\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promotion_by_departments = pd.DataFrame(df.groupby('departments').promotion_last_5years.mean()).sort_values('promotion_last_5years',ascending=False)\n",
    "promotion_by_departments.plot(kind='bar',figsize=(8,4))\n",
    "plt.title(\"Percentage of Promotion by Departments\");\n",
    "\n",
    "promotion_by_departments.T.round(3)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accident_by_departments = pd.DataFrame(df.groupby('salary').work_accident.mean()).sort_values('work_accident',ascending=False)\n",
    "accident_by_departments.plot(kind='bar',figsize=(8,4))\n",
    "plt.title(\"Percentage of Promotion by Salary\");\n",
    "\n",
    "accident_by_departments.T.round(3)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1Gp2f7q2snF"
   },
   "source": [
    "## 3. Cluster Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_onehot  = ['departments']\n",
    "cat_ordinal = ['salary']\n",
    "    \n",
    "cat_for_salary = ['low', 'medium', 'high']\n",
    "\n",
    "\n",
    "#onohotencoder dönüşümü yapacağımız featurları cat_onehot listesinde, ordinalencoder dönüşümü yapacağımız featureları\n",
    "#cat_ordinal listesinde belirtiyoruz.\n",
    "\n",
    "# ordinalencoder dönüşümü yapacağımız featurların hangi sıralama ile numaralandırlacağını model bilmediğinden\n",
    "# bu sıralamayı modele manuel olarak biz veriyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "column_trans = make_column_transformer(\n",
    "                        (OneHotEncoder(handle_unknown=\"ignore\", sparse=False), cat_onehot), \n",
    "                        (OrdinalEncoder(categories= [cat_for_salary]),cat_ordinal),\n",
    "                         remainder='passthrough', # MinMaxScaler()\n",
    "                         verbose_feature_names_out=False) \n",
    "\n",
    "column_trans=column_trans.set_output(transform=\"pandas\")\n",
    "\n",
    "\n",
    "# remainder='passthrough' ile dönüşüm yapılmayan diğer tüm featurları olduğu gibi bırak anlamına gelir.\n",
    "# eğer remainder defaul değeri ile \"drop\" olarak bırakılırsa dönüşüm yapılmayan tüm featurlar df'den drop edilir.\n",
    "# remainder= MinMaxScaler() veya StandardScale() yaparsak dönüşüm yapılmayan featurlar haricindeki diğer featurlara\n",
    "# scale işlem uygulanır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = column_trans.fit_transform(df)\n",
    "df_encoded.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "df_scaled = pd.DataFrame(MinMaxScaler().fit_transform(df_encoded),\n",
    "                         columns=df_encoded.columns)\n",
    "df_scaled.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 18))\n",
    "sns.heatmap(df_encoded.corr(), annot=True)\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "sns.pairplot(df_encoded, diag_kind='kde', diag_kws={'color': 'brown', 'alpha': 0.6}, aspect=1.5 );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn.metrics import silhouette_samples,silhouette_score\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from yellowbrick.cluster import KElbowVisualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import BallTree\n",
    "\n",
    "def hopkins(data_frame, sampling_size):\n",
    "    \"\"\"Assess the clusterability of a dataset. A score between 0 and 1, a score around 0.5 express\n",
    "    no clusterability and a score tending to 0 express a high cluster tendency.\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_frame : numpy array\n",
    "        The input dataset\n",
    "    sampling_size : int\n",
    "        The sampling size which is used to evaluate the number of DataFrame.\n",
    "    Returns\n",
    "    ---------------------\n",
    "    score : float\n",
    "        The hopkins score of the dataset (between 0 and 1)\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn import datasets\n",
    "    >>> from pyclustertend import hopkins\n",
    "    >>> X = datasets.load_iris().data\n",
    "    >>> hopkins(X,150)\n",
    "    0.16\n",
    "    \"\"\"\n",
    "    if type(data_frame) == np.ndarray:\n",
    "        data_frame = pd.DataFrame(data_frame)\n",
    "    # Sample n observations from D : P\n",
    "    if sampling_size > data_frame.shape[0]:\n",
    "        raise Exception(\n",
    "            'The number of sample of sample is bigger than the shape of D')\n",
    "    data_frame_sample = data_frame.sample(n=sampling_size)\n",
    "    # Get the distance to their neirest neighbors in D : X\n",
    "    tree = BallTree(data_frame, leaf_size=2)\n",
    "    dist, _ = tree.query(data_frame_sample, k=2)\n",
    "    data_frame_sample_distances_to_nearest_neighbours = dist[:, 1]\n",
    "    # Randomly simulate n points with the same variation as in D : Q.\n",
    "    max_data_frame = data_frame.max()\n",
    "    min_data_frame = data_frame.min()\n",
    "    uniformly_selected_values_0 = np.random.uniform(min_data_frame[0], max_data_frame[0], sampling_size)\n",
    "    uniformly_selected_values_1 = np.random.uniform(min_data_frame[1], max_data_frame[1], sampling_size)\n",
    "    uniformly_selected_observations = np.column_stack((uniformly_selected_values_0, uniformly_selected_values_1))\n",
    "    if len(max_data_frame) >= 2:\n",
    "        for i in range(2, len(max_data_frame)):\n",
    "            uniformly_selected_values_i = np.random.uniform(min_data_frame[i], max_data_frame[i], sampling_size)\n",
    "            to_stack = (uniformly_selected_observations, uniformly_selected_values_i)\n",
    "            uniformly_selected_observations = np.column_stack(to_stack)\n",
    "    uniformly_selected_observations_df = pd.DataFrame(uniformly_selected_observations)\n",
    "    # Get the distance to their neirest neighbors in D : Y\n",
    "    tree = BallTree(data_frame, leaf_size=2)\n",
    "    dist, _ = tree.query(uniformly_selected_observations_df, k=1)\n",
    "    uniformly_df_distances_to_nearest_neighbours = dist\n",
    "    # return the hopkins score\n",
    "    x = sum(data_frame_sample_distances_to_nearest_neighbours)\n",
    "    y = sum(uniformly_df_distances_to_nearest_neighbours)\n",
    "    if x + y == 0:\n",
    "        raise Exception('The denominator of the hopkins statistics is null')\n",
    "    return x / (x + y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hopkins(df_scaled, df_scaled.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_scaled, diag_kind='kde', diag_kws={'color': 'red', 'alpha': 0.6}, aspect=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 18))\n",
    "sns.heatmap(df_scaled.corr(), annot=True, cmap='coolwarm', linewidth=1, linecolor='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Elbow Method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssd = []\n",
    "\n",
    "K = range(2,11)\n",
    "\n",
    "for k in K:\n",
    "    model = KMeans(n_clusters =k, random_state=42)\n",
    "    model.fit(df_scaled)\n",
    "    ssd.append(model.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(K, ssd, \"bo-\")\n",
    "plt.xlabel(\"Different k values\")\n",
    "plt.ylabel(\"inertia-error\") \n",
    "plt.title(\"elbow method\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "model = KMeans(random_state=42)\n",
    "visualizer = KElbowVisualizer(model, k=(2,11))\n",
    "\n",
    "visualizer.fit(df_scaled)\n",
    "visualizer.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Silhouette Coefficient**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_n_clusters = range(2,11)\n",
    "for num_clusters in range_n_clusters:\n",
    "    # intialise kmeans\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "    kmeans.fit(df_scaled)\n",
    "    cluster_labels = kmeans.labels_\n",
    "    # silhouette score\n",
    "    silhouette_avg = silhouette_score(df_scaled, cluster_labels)\n",
    "    print(f\"For n_clusters={num_clusters}, the silhouette score is {silhouette_avg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Fitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_model1 = KMeans(n_clusters=4, random_state=42)\n",
    "km_model1.fit(df_scaled)\n",
    "\n",
    "df_scaled['ClusterID_4'] = km_model1.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_model2 = KMeans(n_clusters=6, random_state=42)\n",
    "km_model2.fit(df_scaled)\n",
    "\n",
    "df_scaled['ClusterID_6'] = km_model2.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_model3 = KMeans(n_clusters=8, random_state=42)\n",
    "km_model3.fit(df_scaled)\n",
    "\n",
    "df_scaled['ClusterID_8'] = km_model3.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Inertia Score (n=4)    : {km_model1.inertia_}')\n",
    "print(f'Silhouette Score (n=4) : {silhouette_score(df_scaled, km_model1.labels_)}')\n",
    "print()\n",
    "print(f'Inertia Score (n=6)    : {km_model2.inertia_}')\n",
    "print(f'Silhouette Score (n=6) : {silhouette_score(df_scaled, km_model2.labels_)}')\n",
    "print()\n",
    "print(f'Inertia Score (n=8)    : {km_model3.inertia_}')\n",
    "print(f'Silhouette Score (n=8) : {silhouette_score(df_scaled, km_model3.labels_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "model = KMeans(n_clusters=4, random_state=42)\n",
    "visualizer = SilhouetteVisualizer(model)\n",
    "\n",
    "visualizer.fit(df_scaled)\n",
    "visualizer.poof();\n",
    "\n",
    "model = KMeans(n_clusters=6, random_state=42)\n",
    "visualizer = SilhouetteVisualizer(model)\n",
    "\n",
    "visualizer.fit(df_scaled)\n",
    "visualizer.poof();\n",
    "\n",
    "model = KMeans(n_clusters=8, random_state=42)\n",
    "visualizer = SilhouetteVisualizer(model)\n",
    "\n",
    "visualizer.fit(df_scaled)\n",
    "visualizer.poof();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = px.pie(df, values = df_scaled['ClusterID_4'].value_counts(), \n",
    "             names = (df_scaled['ClusterID_4'].value_counts()).index, \n",
    "             title = 'ClusterID_4 Distribution')\n",
    "fig1.show()\n",
    "\n",
    "fig2 = px.pie(df, values = df_scaled['ClusterID_6'].value_counts(), \n",
    "             names = (df_scaled['ClusterID_6'].value_counts()).index, \n",
    "             title = 'ClusterID_6 Distribution')\n",
    "fig2.show()\n",
    "\n",
    "fig3 = px.pie(df, values = df_scaled['ClusterID_8'].value_counts(), \n",
    "             names = (df_scaled['ClusterID_8'].value_counts()).index, \n",
    "             title = 'ClusterID_8 Distribution')\n",
    "fig3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,6))\n",
    "plt.subplot(121)\n",
    "ax1 = sns.countplot(x='ClusterID_6', data=df_scaled)\n",
    "for p in ax1.patches:\n",
    "    ax1.annotate((p.get_height()), (p.get_x()+0.3, p.get_height()+100), fontsize=11)\n",
    "plt.subplot(122)\n",
    "ax2 = sns.countplot(x='ClusterID_8', data=df_scaled)\n",
    "for p in ax2.patches:\n",
    "    ax2.annotate((p.get_height()), (p.get_x()+0.3, p.get_height()+100), fontsize=11)\n",
    "ax1.set_title('Distribution of Clusters For 6-Class', size=13, pad=11)\n",
    "ax2.set_title('Distribution of Clusters For 8-Class', size=13, pad=11)\n",
    "ax1.set_ylim(0, 2500), ax2.set_ylim(0, 2500);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ideal k = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.drop([\"ClusterID_4\", \"ClusterID_6\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,7))\n",
    "\n",
    "plt.subplot(121)\n",
    "centers = km_model3.cluster_centers_\n",
    "sns.scatterplot(data=df_scaled, x='satisfaction_level', y='last_evaluation', hue=df_scaled.ClusterID_8, palette='viridis')\n",
    "plt.scatter(centers[:, 0], centers[:, 2], c='black', s=200, alpha=0.6)\n",
    "plt.title('satisfaction_level-last_evaluation\\n(8-CLUSTERS)', size=14, pad=12)\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 2, sharey=True, figsize=(16, 12))\n",
    "\n",
    "# K Means \"Satisfaction Level vs. average_montly_hours\"\n",
    "axs[0, 0].set_title('K Means \"Satisfaction Level vs. average_montly_hours\"')\n",
    "axs[0, 0].scatter(df_scaled['satisfaction_level'], df_scaled['average_montly_hours'],\n",
    "                  c=df_scaled['ClusterID_8'], cmap='rainbow')\n",
    "\n",
    "# K Means \"Satisfaction Level vs. time_spend_company\"\n",
    "axs[0, 1].set_title('K Means \"Satisfaction Level vs. time_spend_company\"')\n",
    "axs[0, 1].scatter(df_scaled['satisfaction_level'], df_scaled['time_spend_company'],\n",
    "                  c=df_scaled['ClusterID_8'], cmap='rainbow')\n",
    "\n",
    "# K Means \"Satisfaction Level vs. Left\"\n",
    "axs[1, 0].set_title('K Means \"Satisfaction Level vs. Left\"')\n",
    "axs[1, 0].scatter(df_scaled['satisfaction_level'], df_scaled['left'],\n",
    "                  c=df_scaled['ClusterID_8'], cmap='rainbow')\n",
    "\n",
    "# K Means \"Work_accident vs. Left\"\n",
    "axs[1, 1].set_title('K Means \"work_accident vs. Left\"')\n",
    "axs[1, 1].scatter(df_scaled['work_accident'], df_scaled['left'],\n",
    "                  c=df_scaled['ClusterID_8'], cmap='rainbow')\n",
    "\n",
    "# K Means \"Satisfaction Level vs. salary\"\n",
    "axs[2, 0].set_title('K Means \"Satisfaction Level vs. salary\"')\n",
    "axs[2, 0].scatter(df_scaled['satisfaction_level'], df_scaled['salary'],\n",
    "                  c=df_scaled['ClusterID_8'], cmap='rainbow')\n",
    "\n",
    "# K Means \"left vs. salary_high\"\n",
    "axs[2, 1].set_title('K Means \"left vs. salary\"')\n",
    "axs[2, 1].scatter(df_scaled['left'], df_scaled['salary'],\n",
    "                  c=df_scaled['ClusterID_8'], cmap='rainbow')\n",
    "\n",
    "# K Means \"Departments_IT vs. average_montly_hours\" \n",
    "axs[3, 0].set_title('K Means \"departments_IT vs. average_montly_hours\"')\n",
    "axs[3, 0].scatter(df_scaled['departments_IT'], df_scaled['average_montly_hours'],\n",
    "                  c=df_scaled['ClusterID_8'], cmap='rainbow')\n",
    "\n",
    "# K Means \"Departments_technical vs. salary\"\n",
    "axs[3, 1].set_title('K Means \"Departments_technical vs. salary\"')\n",
    "axs[3, 1].scatter(df_scaled['departments_technical'], df_scaled['salary'],\n",
    "                  c=df_scaled['ClusterID_8'], cmap='rainbow')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2, sharey=True, figsize=(16, 12))\n",
    "\n",
    "# K Means \"Satisfaction Level vs. average_montly_hours\"\n",
    "axs[0, 0].set_title('K Means \"Satisfaction Level vs. average_montly_hours\"')\n",
    "axs[0, 0].scatter(df_scaled['satisfaction_level'], df_scaled['average_montly_hours'],\n",
    "                  c=df_scaled['ClusterID_8'], cmap='rainbow')\n",
    "\n",
    "# K Means \"Satisfaction Level vs. time_spend_company\"\n",
    "axs[0, 1].set_title('K Means \"Satisfaction Level vs. time_spend_company\"')\n",
    "axs[0, 1].scatter(df_scaled['satisfaction_level'], df_scaled['time_spend_company'],\n",
    "                  c=df_scaled['ClusterID_8'], cmap='rainbow')\n",
    "\n",
    "# K Means \"Satisfaction Level vs. Left\"\n",
    "axs[1, 0].set_title('K Means \"Satisfaction Level vs. Left\"')\n",
    "axs[1, 0].scatter(df_scaled['satisfaction_level'], df_scaled['left'],\n",
    "                  c=df_scaled['ClusterID_8'], cmap='rainbow')\n",
    "\n",
    "# K Means \"Work_accident vs. Left\"\n",
    "axs[1, 1].set_title('K Means \"work_accident vs. Left\"')\n",
    "axs[1, 1].scatter(df_scaled['work_accident'], df_scaled['left'],\n",
    "                  c=df_scaled['ClusterID_8'], cmap='rainbow')\n",
    "\n",
    "# K Means \"Satisfaction Level vs. promotion_last_5years\"\n",
    "axs[2, 0].set_title('K Means \"Satisfaction Level vs. promotion_last_5years\"')\n",
    "axs[2, 0].scatter(df_scaled['satisfaction_level'], df_scaled['promotion_last_5years'],\n",
    "                  c=df_scaled['ClusterID_8'], cmap='rainbow')\n",
    "\n",
    "# K Means \"Satisfaction Level vs. average_montly_hours\" (duplicate)\n",
    "axs[2, 1].set_title('K Means \"Satisfaction Level vs. average_montly_hours\"')\n",
    "axs[2, 1].scatter(df_scaled['satisfaction_level'], df_scaled['average_montly_hours'],\n",
    "                  c=df_scaled['ClusterID_8'], cmap='rainbow')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "fig = plt.figure(figsize=(14,6))\n",
    "\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "ax1.scatter(df_scaled['satisfaction_level'], df_scaled['time_spend_company'], df_scaled['left'],c=df_scaled.ClusterID_8, cmap='viridis')\n",
    "ax1.set_title('ClusterID-8', fontsize=13)\n",
    "\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "ax2.scatter(df_scaled['average_montly_hours'], df_scaled['last_evaluation'], df_scaled['number_project'],c=df_scaled.ClusterID_8, cmap='viridis')\n",
    "ax2.set_title('ClusterID-8', fontsize=13)\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As a result of the cluster analysis, it was concluded that the most appropriate number of clusters was 8. \n",
    "However, when the visualization is done in accordance with the ideal number of clusters, \n",
    "it has been observed that the ideal clustering does not occur. \n",
    "As a result, it was concluded that this data set is not suitable for clustering with k-means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WpmbaABr2snN"
   },
   "source": [
    "## 4. Predictive Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"HR_Dataset.csv\")\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "X=df.drop([\"left\"], axis=1)\n",
    "y=df[\"left\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_onehot  = ['departments']\n",
    "cat_ordinal = ['salary']\n",
    "    \n",
    "cat_for_salary = ['low', 'medium', 'high']\n",
    "\n",
    "\n",
    "# onohotencoder dönüşümü yapacağımız featurları cat_onehot listesinde, ordinalencoder dönüşümü yapacağımız featureları\n",
    "# cat_ordinal listesinde belirtiyoruz.\n",
    "\n",
    "# ordinalencoder dönüşümü yapacağımız featurların hangi sıralama ile numaralandırlacağını model bilmediğinden\n",
    "# bu sıralamayı modele manuel olarak biz veriyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "column_trans = make_column_transformer(\n",
    "                        (OneHotEncoder(handle_unknown=\"ignore\", sparse=False), cat_onehot), \n",
    "                        (OrdinalEncoder(categories= [cat_for_salary]),cat_ordinal),\n",
    "                         remainder=MinMaxScaler(), # 'passthrough'\n",
    "                         verbose_feature_names_out=False)\n",
    "\n",
    "column_trans = column_trans.set_output(transform=\"pandas\")\n",
    "\n",
    "# remainder='passthrough' ile dönüşüm yapılmayan diğer tüm featurları olduğu gibi bırak anlamına gelir.\n",
    "# eğer remainder defaul değeri ile \"drop\" olarak bırakılırsa dönüşüm yapılmayan tüm featurlar df'den drop edilir.\n",
    "# remainder= MinMaxScaler() veya StandardScale() yaparsak dönüşüm yapılmayan featurlar haricindeki diğer featurlara\n",
    "# scale işlem uygulanır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9P157eX2sn2"
   },
   "source": [
    "### Classification Algorithms\n",
    " - Try at least 4 ML/DL algorithms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st Model: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operations = [(\"encoding\", column_trans),\n",
    "              (\"logistic\", LogisticRegression(class_weight=\"balanced\",\n",
    "                                             max_iter=10000,))] \n",
    "\n",
    "log_model = Pipeline(steps=operations)\n",
    "\n",
    "log_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metric(model, X_train, y_train, X_test, y_test):\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(\"Test_Set\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print()\n",
    "    print(\"Train_Set\")\n",
    "    print(confusion_matrix(y_train, y_train_pred))\n",
    "    print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metric(log_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(log_model, X_test, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = ['precision','recall','f1','accuracy']\n",
    "\n",
    "operations = [(\"encoding\", column_trans),\n",
    "              (\"logistic\", LogisticRegression(class_weight=\"balanced\",\n",
    "                                             max_iter=10000,))] \n",
    "\n",
    "model = Pipeline(steps=operations)\n",
    "\n",
    "scores = cross_validate(model, X_train, y_train,\n",
    "                        scoring = scoring, \n",
    "                        cv = 10,\n",
    "                        return_train_score=True)\n",
    "df_scores = pd.DataFrame(scores, index = range(1, 11))\n",
    "df_scores.mean()[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC (Receiver Operating Curve) and AUC (Area Under Curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay, PrecisionRecallDisplay, roc_auc_score, roc_curve,\\\n",
    "                            average_precision_score, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RocCurveDisplay.from_estimator(log_model, X_test, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PrecisionRecallDisplay.from_estimator(log_model, X_test, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An overview of the predictions with their pred_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = log_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.concat([X_test, y_test], axis=1)\n",
    "test_data[\"pred\"] = y_pred\n",
    "test_data[\"pred_proba\"] = y_pred_proba[:,1]\n",
    "test_data.sample(10)\n",
    "\n",
    "# test datamıza pred ve pred_proba featurlarını ilave ederek modelin prediction işlemini nasıl yaptığını tekrar gözlemliyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_model.predict(X_test)\n",
    "\n",
    "log_recall = recall_score(y_test, y_pred)\n",
    "log_f1 = f1_score(y_test, y_pred)\n",
    "log_AP = average_precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd Model: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operations = [(\"encoding\", column_trans),\n",
    "              (\"RF_model\", RandomForestClassifier(max_depth=10,\n",
    "                                                  class_weight=\"balanced\"))]\n",
    "\n",
    "RF_model = Pipeline(steps=operations)\n",
    "\n",
    "RF_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metric(RF_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(RF_model, X_test, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operations = [(\"encoding\", column_trans),\n",
    "              (\"RF_model\", RandomForestClassifier(max_depth=10,\n",
    "                                                  class_weight=\"balanced\"))]\n",
    "\n",
    "model = Pipeline(steps=operations)\n",
    "\n",
    "scores = cross_validate(model, \n",
    "                        X_train, \n",
    "                        y_train, \n",
    "                        scoring=[\"accuracy\", \n",
    "                                 \"precision_micro\",\n",
    "                                 \"recall_micro\", \n",
    "                                 \"f1_micro\"], \n",
    "                        cv = 10,\n",
    "                        return_train_score=True)\n",
    "df_scores = pd.DataFrame(scores, index = range(1, 11))\n",
    "df_scores.mean()[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PrecisionRecallDisplay.from_estimator(RF_model, X_test, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = RF_model.predict(X_test)\n",
    "\n",
    "RF_recall = recall_score(y_test, y_pred)\n",
    "RF_f1 = f1_score(y_test, y_pred)\n",
    "RF_AP = average_precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3rd Model: KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"HR_Dataset.csv\")\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "df['salary'] = df['salary'].map({'low': 0, 'medium': 1, 'high': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.salary.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_for_departments = ['sales', 'technical', 'support', 'IT', 'RandD', 'product_mng', 'marketing', 'accounting', 'hr', 'management']\n",
    "enc2 = OrdinalEncoder(categories= [cat_for_departments])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc2.fit_transform(df[[\"departments\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc2 = OrdinalEncoder()\n",
    "encoded_departments = enc2.fit_transform(df[[\"departments\"]])\n",
    "df[\"departments\"] = pd.DataFrame(encoded_departments, index=df.index, columns=[\"departments_encoded\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('left', axis=1)\n",
    "y = df[\"left\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operations = [(\"scaler\", MinMaxScaler()), (\"knn\", KNeighborsClassifier(n_neighbors=5))]\n",
    "\n",
    "pipe_model = Pipeline(steps=operations)\n",
    "\n",
    "pipe_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe_model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = pipe_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_pred_proba)\n",
    "my_dict = {\"Actual\": y_test, \"Pred\":y_pred, \"Proba_1\":y_pred_proba[:,1], \"Proba_0\":y_pred_proba[:,0]}\n",
    "pd.DataFrame.from_dict(my_dict).sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metric(model, X_train, y_train, X_test, y_test):\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(\"Test_Set\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print()\n",
    "    print(\"Train_Set\")\n",
    "    print(confusion_matrix(y_train, y_train_pred))\n",
    "    print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metric(pipe_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#operations = [(\"scaler\", MinMaxScaler()), (\"knn\", KNeighborsClassifier())]\n",
    "#knn_model = Pipeline(steps=operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k_values= range(1,30)\n",
    "#param_grid = {\"knn__n_neighbors\":k_values, \"knn__p\": [1,2], \"knn__weights\": ['uniform', \"distance\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn_grid_model = GridSearchCV(knn_model, param_grid, cv=10, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn_grid_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn_grid_model.best_params_    {'knn__n_neighbors': 10, 'knn__p': 2, 'knn__weights': 'distance'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn_grid_model.best_index_     39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(knn_grid_model.cv_results_).loc[39, [\"mean_test_score\", \"mean_train_score\"]]\n",
    "#mean_test_score     0.970582\n",
    "#mean_train_score         1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn_grid_model.best_score_       0.9705815262718932"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval_metric(knn_grid_model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "\n",
    "#Test_Set\n",
    "#[[2224   62]\n",
    " #[  23  691]]\n",
    " #             precision    recall  f1-score   support\n",
    "\n",
    " #          0       0.99      0.97      0.98      2286\n",
    " #         1       0.92      0.97      0.94       714\n",
    "\n",
    "  #  accuracy                           0.97      3000\n",
    "  # macro avg       0.95      0.97      0.96      3000\n",
    "#weighted avg       0.97      0.97      0.97      3000\n",
    "\n",
    "\n",
    "#Train_Set\n",
    "#[[9142    0]\n",
    "# [   0 2857]]\n",
    "#              precision    recall  f1-score   support\n",
    "\n",
    "#           0       1.00      1.00      1.00      9142\n",
    "#           1       1.00      1.00      1.00      2857\n",
    "\n",
    "#    accuracy                           1.00     11999\n",
    "#   macro avg       1.00      1.00      1.00     11999\n",
    "#weighted avg       1.00      1.00      1.00     11999\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PrecisionRecallDisplay.from_estimator(pipe_model, X_test, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe_model.predict(X_test)\n",
    "\n",
    "knn_recall = recall_score(y_test, y_pred)\n",
    "knn_f1 = f1_score(y_test, y_pred)\n",
    "knn_AP = average_precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4th Model: XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"HR_Dataset.csv\")\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "X=df.drop([\"left\"], axis=1)\n",
    "y=df[\"left\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = X_train.select_dtypes(\"object\").columns\n",
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_enc = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "column_trans = make_column_transformer((ord_enc, cat), remainder=MinMaxScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operations_xgb = [(\"OrdinalEncoder\", column_trans),\n",
    "                  (\"XGB_model\", XGBClassifier(random_state=101))]\n",
    "\n",
    "pipe_model_xgb = Pipeline(steps=operations_xgb)\n",
    "\n",
    "pipe_model_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metric(pipe_model_xgb, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "classes_weights = class_weight.compute_sample_weight(class_weight='balanced',\n",
    "                                                     y=y_train)\n",
    "classes_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_model_xgb.fit(X_train,\n",
    "                   y_train,\n",
    "                   XGB_model__sample_weight=classes_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metric(pipe_model_xgb, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_xgb = {\"precision_1\" : make_scorer(precision_score, average = None, labels =[1]),\n",
    "           \"recall_1\" : make_scorer(recall_score, average = None, labels =[1]),\n",
    "           \"f1_1\" : make_scorer(f1_score, average = None, labels =[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operations_xgb = [(\"OrdinalEncoder\", column_trans),\n",
    "                  (\"XGB_model\", XGBClassifier(random_state=101))]\n",
    "\n",
    "model = Pipeline(steps=operations_xgb)\n",
    "\n",
    "scores = cross_validate(model,\n",
    "                        X_train,\n",
    "                        y_train,\n",
    "                        scoring=scoring_xgb,\n",
    "                        cv=5,\n",
    "                        return_train_score=True,\n",
    "                        fit_params={\"XGB_model__sample_weight\":classes_weights})\n",
    "df_scores = pd.DataFrame(scores, index = range(1, 6))\n",
    "df_scores.mean()[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Model GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"XGB_model__n_estimators\":[110, 150, 200],\n",
    "              'XGB_model__max_depth':[5,10,15,20],\n",
    "              \"XGB_model__learning_rate\": [0.1, 0.15, 0.2],\n",
    "              \"XGB_model__subsample\":[0.8, 1],\n",
    "              \"XGB_model__colsample_bytree\":[0.7, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operations_xgb = [(\"OrdinalEncoder\", column_trans),\n",
    "                  (\"XGB_model\", XGBClassifier(random_state=101))]\n",
    "\n",
    "model = Pipeline(steps=operations_xgb)\n",
    "\n",
    "xgb_grid_model = GridSearchCV(model,\n",
    "                              param_grid,\n",
    "                              scoring=make_scorer(recall_score, average = None, labels =[1]),\n",
    "                              cv=5,\n",
    "                              n_jobs=-1,\n",
    "                              return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_grid_model.fit(X_train,\n",
    "                   y_train,\n",
    "                   XGB_model__sample_weight=classes_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(xgb_grid_model.cv_results_).loc[xgb_grid_model.best_index_, [\"mean_test_score\", \"mean_train_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_grid_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metric(xgb_grid_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operations_xgb = [(\"OrdinalEncoder\", column_trans),\n",
    "                  (\"XGB_model\", XGBClassifier(colsample_bytree=1,\n",
    "                                              learning_rate=0.15,\n",
    "                                              max_depth=5,\n",
    "                                              n_estimators=200,\n",
    "                                              subsample=0.8,\n",
    "                                              random_state=101))]\n",
    "\n",
    "model = Pipeline(steps=operations_xgb)\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          XGB_model__sample_weight=classes_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metric(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "xgb_recall = recall_score(y_test, y_pred)\n",
    "xgb_f1 = f1_score(y_test, y_pred)\n",
    "xgb_AP = average_precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikitplot as skplt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikitplot.metrics import plot_roc, precision_recall_curve\n",
    "\n",
    "\n",
    "operations_xgb = [(\"OrdinalEncoder\", column_trans),\n",
    "                  (\"XGB_model\", XGBClassifier(colsample_bytree=0.7,\n",
    "                                              learning_rate=0.2,\n",
    "                                              max_depth=5,\n",
    "                                              n_estimators=200,\n",
    "                                              subsample=0.8,\n",
    "                                              random_state=101))]\n",
    "\n",
    "model = Pipeline(steps=operations_xgb)\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          XGB_model__sample_weight=classes_weights)\n",
    "\n",
    "y_pred_proba = model.predict_proba(X_test)\n",
    "\n",
    "skplt.metrics.plot_precision_recall(y_test, y_pred_proba)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ord_enc = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "column_trans = make_column_transformer((ord_enc, cat), remainder=MinMaxScaler())\n",
    "operations = [(\"OrdinalEncoder\", column_trans), (\"XGB_model\", XGBClassifier(random_state=101,\n",
    "                                                                            colsample_bytree = 0.7,\n",
    "                                                                            subsample= 0.8,\n",
    "                                                                            learning_rate= 0.2,\n",
    "                                                                            max_depth= 5,\n",
    "                                                                            n_estimators= 200\n",
    "                                                                           ))]\n",
    "\n",
    "\n",
    "model = Pipeline(steps=operations)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "feats = pd.DataFrame(index=X.columns, data=model[\"XGB_model\"].feature_importances_, columns=['xgb_importance'])\n",
    "xgb_imp_feats = feats.sort_values(\"xgb_importance\", ascending=False)\n",
    "xgb_imp_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(data=xgb_imp_feats, x=xgb_imp_feats.index,y='xgb_importance')\n",
    "ax.bar_label(ax.containers[0],fmt=\"%.3f\")\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['left', \"satisfaction_level\", \"last_evaluation\", \"work_accident\", \"departments\"], axis = 1)\n",
    "y = df['left']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = X_train.select_dtypes(\"object\").columns\n",
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ord_enc = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "column_trans = make_column_transformer((ord_enc, cat), remainder=MinMaxScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operations = [(\"OrdinalEncoder\", column_trans), (\"XGB_model\", XGBClassifier(random_state=101))]\n",
    "\n",
    "XGB_pipe_model = Pipeline(steps=operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_pipe_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metric(XGB_pipe_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"XGB_model__n_estimators\":[110, 150, 200],\n",
    "              'XGB_model__max_depth':[14,15,18,25],\n",
    "              \"XGB_model__learning_rate\": [0.1, 0.15, 0.2],\n",
    "              \"XGB_model__subsample\":[0.8, 1],\n",
    "              \"XGB_model__colsample_bytree\":[0.7, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_imp_fea_model = Pipeline(steps=operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_fea_grid = GridSearchCV(xgb_imp_fea_model, param_grid, scoring = \"recall\", verbose=2, n_jobs = -1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_fea_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metric(xgb_fea_grid, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5th Model: ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"HR_Dataset.csv\")\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "X=df.drop([\"left\"], axis=1)\n",
    "y=df[\"left\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    stratify=y,\n",
    "                                                    test_size=0.10,\n",
    "                                                    random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,\n",
    "                                                  y_train,\n",
    "                                                  stratify=y_train,\n",
    "                                                  test_size=0.1,\n",
    "                                                  random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "cat_col = X_train.select_dtypes(include=['object', 'bool']).columns\n",
    "\n",
    "encoder = OneHotEncoder(categories=\"auto\",\n",
    "                        sparse=False, \n",
    "                        handle_unknown=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "transformers = [('cat', encoder, cat_col)]\n",
    "\n",
    "col_transformer = ColumnTransformer(transformers=transformers,\n",
    "                                    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = col_transformer.fit_transform(X_train)\n",
    "X_val = col_transformer.transform(X_val)\n",
    "X_test = col_transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer Architecture Building and Compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from livelossplot import PlotLossesKerasTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dense(8, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "opt = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt, \n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"Recall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor=\"val_loss\",\n",
    "                           mode=\"auto\",\n",
    "                           verbose=1,\n",
    "                           patience=10,\n",
    "                           restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                  classes=np.unique(y_train),\n",
    "                                                  y=y_train)\n",
    "class_weights = {0: class_weights[0], 1: class_weights[1]}\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=X_train,\n",
    "          y=y_train,\n",
    "          validation_data=(X_val, y_val),\n",
    "          batch_size=128,\n",
    "          epochs=200,\n",
    "          verbose=1,\n",
    "          callbacks=[early_stop, PlotLossesKerasTF()],\n",
    "          class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (model.predict(X_test) > .5).astype(\"int32\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score,\\\n",
    "                            f1_score, precision_recall_curve,\\\n",
    "                            average_precision_score\n",
    "y_pred_proba = model.predict(X_test)\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
    "plt.plot(recalls, precisions, label='ANN')\n",
    "plt.xlabel('recalls')\n",
    "plt.ylabel('precisions')\n",
    "plt.title('Precision-Recall curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from tensorflow.keras.optimizers import Adam, Adadelta, RMSprop, Nadam "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_metric = \"Recall\"\n",
    "batch_size = 300\n",
    "def create_model(trial):\n",
    "    # Some hyperparameters we want to optimize\n",
    "    n_units1 = trial.suggest_int('n_units1', 8, 128)\n",
    "    n_units2 = trial.suggest_int('n_units2', 8, 128)\n",
    "    optimizer = trial.suggest_categorical(\"optimizer\",\n",
    "                                          [Adam, Adadelta, RMSprop, Nadam])\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1.3e-1)\n",
    "\n",
    "    tf.random.set_seed(42)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n_units1, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(Dense(n_units2, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer(learning_rate=learning_rate),\n",
    "                  metrics=[trial_metric])\n",
    "    return model\n",
    "\n",
    "def objective(trial):\n",
    "    model = create_model(trial)\n",
    "    w0 = trial.suggest_loguniform(\"w0\", 0.01, 5)\n",
    "    w1 = trial.suggest_loguniform(\"w1\", 0.01, 5)\n",
    "    model.fit(X_train,\n",
    "              y_train,\n",
    "              validation_data=(X_val, y_val),\n",
    "              batch_size=batch_size,\n",
    "              epochs=200,\n",
    "              callbacks=[early_stop],\n",
    "              class_weight={0: w0, 1: w1},\n",
    "              verbose=0)\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "    if score > .86 : # after this threshold model gets terrible scores for class 0\n",
    "        score = score * 0\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=25)\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit1, unit2, optimizer, lr, w0, w1 = (study.best_params['n_units1'],\n",
    "                               study.best_params['n_units2'],\n",
    "                               study.best_params['optimizer'],\n",
    "                               study.best_params['learning_rate'], \n",
    "                               study.best_params['w0'],\n",
    "                               study.best_params['w1'] )\n",
    "tf.random.set_seed(42)\n",
    "model = Sequential()\n",
    "model.add(Dense(unit1, activation=\"relu\"))\n",
    "model.add(Dense(unit2, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "opt = optimizer(learning_rate=lr)\n",
    "model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=[\"Recall\"])\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          validation_data=(X_val, y_val),\n",
    "          batch_size=300,\n",
    "          epochs=200,\n",
    "          callbacks=[early_stop],\n",
    "          verbose=1,\n",
    "         class_weight={0: w0, 1: w1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = model.predict(X_test)\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
    "plt.plot(recalls, precisions, label='ANN')\n",
    "plt.xlabel('recalls')\n",
    "plt.ylabel('precisions')\n",
    "plt.title('Precision-Recall curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna_pre_score = average_precision_score(y_test, y_pred_proba)\n",
    "optuna_pre_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna_weighted_f1 = f1_score(y_test, y_pred)\n",
    "optuna_weighted_recall = recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "model = Sequential()\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dense(8, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "opt = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt, \n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"Recall\"])\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\",\n",
    "                           mode=\"auto\",\n",
    "                           verbose=1,\n",
    "                           patience=10,\n",
    "                           restore_best_weights = True)\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                  classes=np.unique(y_train),\n",
    "                                                  y=y_train)\n",
    "class_weights = {0: class_weights[0], 1: class_weights[1]}\n",
    "model.fit(x=X_train,\n",
    "          y=y_train,\n",
    "          validation_data=(X_val, y_val),\n",
    "          batch_size=128,\n",
    "          epochs=200,\n",
    "          verbose=1,\n",
    "          callbacks=[early_stop, PlotLossesKerasTF()],\n",
    "          class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df = pd.DataFrame(model.history.history)\n",
    "loss_df.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (model.predict(X_test) > .5).astype(\"int32\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_pre_score = average_precision_score(y_test, y_pred_proba)\n",
    "weighted_pre_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_f1 = f1_score(y_test, y_pred)\n",
    "weighted_recall = recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MefRCx542snY"
   },
   "source": [
    "## MODEL COMPARASION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = pd.DataFrame({\n",
    "    \"Model\": [\"XGB\",\"RF\",\"KNN\",\"ANN_Weighted\", \"ANN_Optuna\", \"Logistic Regression\"],\n",
    "    \"F1\": [xgb_f1, RF_f1, knn_f1,log_f1, weighted_f1, optuna_weighted_f1],\n",
    "    \"Recall\": [xgb_recall ,RF_recall,log_recall, knn_recall, weighted_recall, optuna_weighted_recall],\n",
    "    \"AP\": [xgb_AP,RF_AP,log_AP,knn_AP, weighted_pre_score, optuna_pre_score]\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def labels(ax):\n",
    "    for p in ax.patches:\n",
    "        width = p.get_width()  # get bar length\n",
    "        ax.text(\n",
    "            width,  # set the text at 1 unit right of the bar\n",
    "            p.get_y() +\n",
    "            p.get_height() / 2,  # get Y coordinate + X coordinate / 2\n",
    "            '{:1.3f}'.format(width),  # set variable to display, 2 decimals\n",
    "            ha='left',  # horizontal alignment\n",
    "            va='center')  # vertical alignment\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.subplot(311)\n",
    "compare = compare.sort_values(by=\"F1\", ascending=False)\n",
    "ax = sns.barplot(x=\"F1\", y=\"Model\", data=compare, palette=\"Blues_d\")\n",
    "labels(ax)\n",
    "\n",
    "plt.subplot(312)\n",
    "compare = compare.sort_values(by=\"Recall\", ascending=False)\n",
    "ax = sns.barplot(x=\"Recall\", y=\"Model\", data=compare, palette=\"Blues_d\")\n",
    "labels(ax)\n",
    "\n",
    "plt.subplot(313)\n",
    "compare = compare.sort_values(by=\"AP\", ascending=False)\n",
    "ax = sns.barplot(x=\"AP\", y=\"Model\", data=compare, palette=\"Blues_d\")\n",
    "labels(ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "XG Booost is Champion. Lets continue with XGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSUOz5302snx"
   },
   "source": [
    "## FINAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"HR_Dataset.csv\")\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "X=df.drop([\"left\"], axis=1)\n",
    "y=df[\"left\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = X_train.select_dtypes(\"object\").columns\n",
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_enc = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "column_trans = make_column_transformer((ord_enc, cat), remainder=MinMaxScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operations_xgb = [(\"OrdinalEncoder\", column_trans),\n",
    "                  (\"XGB_model\", XGBClassifier(colsample_bytree=1,\n",
    "                                              learning_rate=0.15,\n",
    "                                              max_depth=5,\n",
    "                                              n_estimators=200,\n",
    "                                              subsample=0.8,\n",
    "                                              random_state=101))]\n",
    "\n",
    "model = Pipeline(steps=operations_xgb)\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          XGB_model__sample_weight=classes_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metric(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hv7E8XsazFMM"
   },
   "source": [
    "## 5. Model Deployement\n",
    "\n",
    "You cooked the food in the kitchen and moved on to the serving stage. The question is how do you showcase your work to others? Model Deployement helps you showcase your work to the world and make better decisions with it. But, deploying a model can get a little tricky at times. Before deploying the model, many things such as data storage, preprocessing, model building and monitoring need to be studied. Streamlit is a popular open source framework used by data scientists for model distribution.\n",
    "\n",
    "Deployment of machine learning models, means making your models available to your other business systems. By deploying models, other systems can send data to them and get their predictions, which are in turn populated back into the company systems. Through machine learning model deployment, can begin to take full advantage of the model you built.\n",
    "\n",
    "Data science is concerned with how to build machine learning models, which algorithm is more predictive, how to design features, and what variables to use to make the models more accurate. However, how these models are actually used is often neglected. And yet this is the most important step in the machine learning pipline. Only when a model is fully integrated with the business systems, real values ​​can be extract from its predictions.\n",
    "\n",
    "After doing the following operations in this notebook, jump to new .py file and create your web app with Streamlit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5pwXBOkJPeM"
   },
   "source": [
    "### Save and Export the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     11428\n",
      "           1       1.00      0.98      0.99      3571\n",
      "\n",
      "    accuracy                           0.99     14999\n",
      "   macro avg       0.99      0.99      0.99     14999\n",
      "weighted avg       0.99      0.99      0.99     14999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"HR_Dataset.csv\")\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "X=df.drop([\"left\"], axis=1)\n",
    "y=df[\"left\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n",
    "cat = X_train.select_dtypes(\"object\").columns\n",
    "ord_enc = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "column_trans = make_column_transformer((ord_enc, cat), remainder=MinMaxScaler())\n",
    "\n",
    "X_trans = column_trans.fit_transform(X)\n",
    "pickle.dump(column_trans, open('transformer', 'wb'))\n",
    "final_model = XGBClassifier(colsample_bytree=1,\n",
    "                                              learning_rate=0.15,\n",
    "                                              max_depth=5,\n",
    "                                              n_estimators=200,\n",
    "                                              subsample=0.8,\n",
    "                                              random_state=101)\n",
    "final_model.fit(X_trans, y)\n",
    "pickle.dump(final_model, open('final_model', 'wb'))\n",
    "\n",
    "y_pred = final_model.predict(X_trans)\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['satisfaction_level', 'last_evaluation', 'number_project',\n",
       "       'average_montly_hours', 'time_spend_company', 'work_accident',\n",
       "       'promotion_last_5years', 'departments', 'salary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sales', 'accounting', 'hr', 'technical', 'support', 'management',\n",
       "       'IT', 'product_mng', 'marketing', 'RandD'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.departments.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "90HfPd4w2sn1"
   },
   "source": [
    "####  Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = pickle.load(open('final_model', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_transformer = pickle.load(open('transformer', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=list(X.columns)\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[[55]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {\n",
    "    \"satisfaction_level\": 0.37,\n",
    "    \"last_evaluation\": 0.46,\n",
    "    \"number_project\": 2,\n",
    "    \"average_montly_hours\":140,\n",
    "    \"time_spend_company\": 3,\n",
    "    'work_accident' :0,\n",
    "    'promotion_last_5years' : 0,\n",
    "    \"departments\" : \"support\",\n",
    "    \"salary\" : \"low\"\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.DataFrame([my_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>work_accident</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>departments</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.46</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>support</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  last_evaluation  number_project  average_montly_hours  \\\n",
       "0                0.37             0.46               2                   140   \n",
       "\n",
       "   time_spend_company  work_accident  promotion_last_5years departments salary  \n",
       "0                   3              0                      0     support    low  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.        , 1.        , 0.30769231, 0.15625   , 0.        ,\n",
       "        0.20560748, 0.125     , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = final_model_transformer.transform(df0)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "prediction = final_model.predict(df1)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aD6JV41czCKr"
   },
   "source": [
    "___\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"https://docs.google.com/uc?id=1lY0Uj5R04yMY3-ZppPWxqCr5pvBLYPnV\" class=\"img-fluid\" alt=\"CLRSWY\"></p>\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Hv7E8XsazFMM"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "b91502e98c93ec413571a3c4a71c4e7e2f090119475bdef759aa0802c5125d05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
